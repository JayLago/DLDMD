{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '../../')\n",
    "import DLDMD as dl\n",
    "import LossDLDMD as lf\n",
    "import Data as dat\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edmd(x, num_pred):\n",
    "    x = tf.transpose(x, perm=[0, 2, 1])\n",
    "    x_m = x[:, :, :-1]\n",
    "    x_p = x[:, :, 1:]\n",
    "    \n",
    "    S, U, V = tf.linalg.svd(x_m, compute_uv=True, full_matrices=False)\n",
    "    sm = np.max(S)\n",
    "    r = S.shape[-1]\n",
    "    Sri = tf.linalg.diag(1./S[:, :r])\n",
    "    Ur = U[:, :, :r]\n",
    "    Urh = tf.linalg.adjoint(Ur)\n",
    "    Vr = V[:, :, :r]\n",
    "    \n",
    "    kmat = x_p @ Vr @ Sri @ Urh\n",
    "    evals, evecs = tf.linalg.eig(kmat)\n",
    "    phim = tf.linalg.solve(evecs, tf.cast(x_m, dtype=tf.complex128))\n",
    "    x0 = phim[:, :, 0]\n",
    "    x0 = x0[:, :, tf.newaxis]\n",
    "    \n",
    "    pred = tf.TensorArray(tf.complex128, size=num_pred)\n",
    "    pred = pred.write(0, evecs @ x0)\n",
    "    evals_iter = tf.identity(evals)\n",
    "    for ii in range(num_pred):\n",
    "        tmp = evecs @ tf.linalg.diag(evals_iter) @ x0\n",
    "        pred = pred.write(ii, tmp)\n",
    "        evals_iter = evals_iter * evals\n",
    "    pred = tf.transpose(tf.squeeze(pred.stack()), perm=[1, 2, 0])\n",
    "    return phim, evals, evecs, pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Figure parameters\n",
    "plot_save_path = './analysis_results/'\n",
    "font = {'family': 'DejaVu Sans', 'size': 18}\n",
    "matplotlib.rc('font', **font)\n",
    "fontsize = 18\n",
    "figsize = (15, 10)\n",
    "dpisave = 300\n",
    "\n",
    "# Initialize the compute device\n",
    "DEVICE = '/GPU:0'\n",
    "GPUS = tf.config.experimental.list_physical_devices('GPU')\n",
    "if GPUS:\n",
    "    try:\n",
    "        for gpu in GPUS:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "else:\n",
    "    DEVICE = '/CPU:0'\n",
    "\n",
    "tf.keras.backend.set_floatx('float64')\n",
    "print(\"TensorFlow version: {}\".format(tf.__version__))\n",
    "print(\"Eager execution: {}\".format(tf.executing_eagerly()))\n",
    "print(\"Num GPUs available: {}\".format(len(GPUS)))\n",
    "print(\"Running on device: {}\".format(DEVICE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Load model and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# SET THIS PATH (w/o file extension!). Both '.pkl' and '.h5' files should have same name\n",
    "model_path = './trained_models/van_der_pol_2021-10-05-1309/epoch_100_loss_-1.83'\n",
    "model_hyp_params = model_path + '.pkl'\n",
    "model_weights = model_path + '.h5'\n",
    "\n",
    "# Load the hyper parameters\n",
    "hyp_params = pickle.load(open(model_hyp_params, 'rb'))\n",
    "\n",
    "# Set Tensorflow backend precision\n",
    "tf.keras.backend.set_floatx(hyp_params['precision'])\n",
    "print(\"Using precision: {}\\n\".format(tf.keras.backend.floatx()))\n",
    "\n",
    "# Load test data\n",
    "test_data = pickle.load(open('data_test.pkl', 'rb'))\n",
    "\n",
    "# Fix hyper parameters for running the model on test data\n",
    "hyp_params['pretrain'] = False\n",
    "hyp_params['batch_size'] = 200\n",
    "\n",
    "# Just examine 1 batch for now\n",
    "test_data = test_data[:hyp_params['batch_size'], :, :]\n",
    "\n",
    "# Load the trained DLDMD model weights\n",
    "model = dl.DLDMD(hyp_params)\n",
    "model(test_data)\n",
    "model.load_weights(model_weights)\n",
    "\n",
    "# Initialize the loss function\n",
    "loss = lf.LossDLDMD(hyp_params)\n",
    "\n",
    "print(\"Test data shape: {}\".format(test_data.shape))\n",
    "print(\"Number of prediction steps: \", model.num_pred_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Run the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with tf.device(DEVICE):\n",
    "    preds = model(test_data, training=False)\n",
    "    losses = loss(preds, test_data)\n",
    "\n",
    "[y, x_ae, x_adv, y_adv, weights, evals, evecs, phi] = preds\n",
    "print(\"Loss: {loss:2.7f}\".format(loss=losses.numpy()))\n",
    "print(\"Log10 Loss: {loss:2.7f}\".format(loss=np.log10(losses.numpy())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run standard DMD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard DMD on the unencoded data\n",
    "[phim, evals, evecs, x_dmd] = edmd(test_data, num_pred=test_data.shape[1])\n",
    "x_dmd = np.real(tf.transpose(x_dmd, perm=[0, 2, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Visualize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fs = 20\n",
    "ts = 20\n",
    "lw = 2.0\n",
    "ms = 20.0\n",
    "figsize = (20, 20)\n",
    "skip = 8\n",
    "\n",
    "# DLDMD reconstruction\n",
    "fig = plt.figure(1, figsize=figsize)\n",
    "for ii in range(0, test_data.shape[0], skip):\n",
    "    plt.plot(test_data[ii, :, 0], test_data[ii, :, 1], 'k', linestyle='solid', lw=lw)\n",
    "    plt.plot(x_adv[ii, :, 0], x_adv[ii, :, 1], 'k', linestyle='dotted', ms=ms)\n",
    "plt.plot(test_data[ii, :, 0], test_data[ii, :, 1], 'k', linestyle='solid', lw=lw, label='Test data')\n",
    "plt.plot(x_adv[ii, 0, 0], x_adv[ii, 0, 1], 'k', linestyle='dotted', ms=20*ms, label='DLDMD')\n",
    "plt.xlabel(r'$x$', fontsize=fs)\n",
    "plt.ylabel(r'$\\dot{x}$', fontsize=fs)\n",
    "plt.legend(fontsize=fs, loc='upper left')\n",
    "plt.axis('equal')\n",
    "ax = plt.gca()\n",
    "ax.tick_params(axis='both', which='major', labelsize=ts)\n",
    "ax.tick_params(axis='both', which='minor', labelsize=ts)\n",
    "\n",
    "# DMD reconstruction\n",
    "fig = plt.figure(2, figsize=figsize)\n",
    "for ii in range(0, test_data.shape[0], skip):\n",
    "    plt.plot(test_data[ii, :, 0], test_data[ii, :, 1], 'k', linestyle='solid', lw=lw)\n",
    "    plt.plot(x_dmd[ii, :, 0], x_dmd[ii, :, 1], 'k', linestyle='dotted', ms=ms)\n",
    "plt.plot(test_data[ii, :, 0], test_data[ii, :, 1], 'k', linestyle='solid', lw=lw, label='Test data')\n",
    "plt.plot(x_dmd[ii, 0, 0], x_dmd[ii, 0, 1], 'k', linestyle='dotted', ms=20*ms, label='DMD')\n",
    "plt.xlabel(r'$x$', fontsize=fs)\n",
    "plt.ylabel(r'$\\dot{x}$', fontsize=fs)\n",
    "plt.legend(fontsize=fs, loc='upper left')\n",
    "plt.axis('equal')\n",
    "ax = plt.gca()\n",
    "ax.tick_params(axis='both', which='major', labelsize=ts)\n",
    "ax.tick_params(axis='both', which='minor', labelsize=ts)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

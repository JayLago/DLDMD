{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '../../')\n",
    "import DLDMD as dl\n",
    "import LossDLDMD as lf\n",
    "import Data as dat\n",
    "import Training as tr\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cpinv(A):\n",
    "    R = tf.math.real(A)\n",
    "    C = tf.math.imag(A)\n",
    "    r0 = tf.linalg.pinv(R) @ C\n",
    "    y11 = tf.linalg.pinv(C @ r0 + R)\n",
    "    y10 = -r0 @ y11\n",
    "    return tf.cast(tf.complex(y11, y10), dtype=A.dtype)\n",
    "\n",
    "def dmd(x, num_pred, t_final, delta_t):\n",
    "    x = tf.transpose(x, perm=[0, 2, 1])\n",
    "    x_m = x[:, :, :-1]\n",
    "    x_p = x[:, :, 1:]\n",
    "    S, U, Vh = tf.linalg.svd(x_m, compute_uv=True, full_matrices=False)\n",
    "    S = tf.linalg.diag(S)\n",
    "    r = S.shape[-1]\n",
    "    Si = tf.linalg.pinv(S)\n",
    "    U = U[:, :, :r]\n",
    "    Ut = tf.transpose(U, conjugate=True, perm=[0, 2, 1])\n",
    "    Vh = Vh[:, :, :r]\n",
    "    A = Ut @ (x_p @ (Vh @ Si))\n",
    "    Lam, W = tf.linalg.eig(A)\n",
    "    Phi = tf.cast(((x_p @ Vh) @ Si), dtype=tf.complex128) @ W\n",
    "    Phi_inv = cpinv(Phi)\n",
    "    y0 = tf.cast(x_m[:, :, 0], dtype=tf.complex128)\n",
    "    b = tf.linalg.matvec(Phi_inv, y0)\n",
    "    Psi = tf.TensorArray(tf.complex128, size=num_pred)\n",
    "    tpred = tf.cast(tf.linspace(0, t_final, num_pred), dtype=tf.complex128)\n",
    "    for ii, tstep in enumerate(tpred):\n",
    "        Psi = Psi.write(ii, tf.math.multiply(tf.math.pow(Lam, tstep / delta_t), b))\n",
    "    Psi = tf.transpose(Psi.stack(), perm=[1, 2, 0])\n",
    "    x_adv = Phi @ Psi\n",
    "    x_adv = tf.transpose(x_adv, perm=[0, 2, 1])\n",
    "    x_adv_real = tf.math.real(x_adv)\n",
    "    x_adv_imag = tf.math.imag(x_adv)\n",
    "    return x_adv_real, x_adv_imag, Lam, Phi, b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure parameters\n",
    "plot_save_path = './analysis_results/'\n",
    "font = {'family': 'DejaVu Sans', 'size': 18}\n",
    "matplotlib.rc('font', **font)\n",
    "fontsize = 18\n",
    "figsize = (15, 10)\n",
    "dpisave = 300\n",
    "\n",
    "# Initialize the compute device\n",
    "DEVICE = '/GPU:0'\n",
    "GPUS = tf.config.experimental.list_physical_devices('GPU')\n",
    "if GPUS:\n",
    "    try:\n",
    "        for gpu in GPUS:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "else:\n",
    "    DEVICE = '/CPU:0'\n",
    "    \n",
    "tf.keras.backend.set_floatx('float64')  # !! Set precision for the entire model here\n",
    "print(\"TensorFlow version: {}\".format(tf.__version__))\n",
    "print(\"Eager execution: {}\".format(tf.executing_eagerly()))\n",
    "print(\"Num GPUs Available: {}\".format(len(GPUS)))\n",
    "print(\"Training at precision: {}\".format(tf.keras.backend.floatx()))\n",
    "print(\"Training on device: {}\".format(DEVICE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# SET THIS PATH (w/o file extension). Both '.pkl' and '.h5' files should have same name\n",
    "model_path = './trained_models//'\n",
    "\n",
    "# Load the hyper parameters\n",
    "hyp_params = pickle.load(open(model_path + '.pkl', 'rb'))\n",
    "\n",
    "# Set Tensorflow backend precision\n",
    "tf.keras.backend.set_floatx(hyp_params['precision'])\n",
    "print(\"Using precision: {}\\n\".format(tf.keras.backend.floatx()))\n",
    "\n",
    "# Load evenly spaced rings for test trajectories (from Lusch et al 2018)\n",
    "test_data = dat.data_maker_fluid_flow_slow(r_lower=0, r_upper=1.1, t_lower=0, t_upper=2*np.pi, \n",
    "                                           n_ic=20, dt=hyp_params['delta_t'],\n",
    "tf=hyp_params['time_final'])\n",
    "test_data = tf.cast(test_data, dtype=hyp_params['precision'])\n",
    "print(\"Test data shape: {}\".format(test_data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Fix hyper parameters for running the model on test data\n",
    "hyp_params['pretrain'] = False\n",
    "hyp_params['batch_size'] = test_data.shape[0]\n",
    "hyp_params['num_time_steps'] = test_data.shape[1]\n",
    "hyp_params['latent_dim'] = test_data.shape[2]\n",
    "hyp_params['phys_dim'] = test_data.shape[2]\n",
    "\n",
    "# Load the trained DLDMD model weights\n",
    "model = dl.DLDMD(hyp_params)\n",
    "model.num_pred_steps = model.num_time_steps\n",
    "model.time_final = int(model.num_time_steps*model.delta_t)\n",
    "model(test_data)\n",
    "model.load_weights(model_path + '.h5')\n",
    "\n",
    "# Initialize the loss function\n",
    "loss = lf.LossDLDMD(hyp_params)\n",
    "print(\"Number of prediction steps: \", model.num_pred_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the DLDMD model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with tf.device(DEVICE):\n",
    "    [y, x_ae, x_adv, y_adv_real, y_adv_imag, weights, Lam, Phi, b] = model(test_data, training=False)\n",
    "    losses = loss([y, x_ae, x_adv, y_adv_real, y_adv_imag, weights, Lam, Phi, b], test_data)\n",
    "    y_adv = y_adv_real\n",
    "\n",
    "print(\"Loss: {loss:2.7f}\".format(loss=losses.numpy()))\n",
    "print(\"Log10 Loss: {loss:2.7f}\".format(loss=np.log10(losses.numpy())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run standard DMD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Standard DMD on the unencoded data\n",
    "[x_dmd_r, x_dmd_i, Lam_dmd, Phi_dmd, b_dmd] = dmd(test_data, num_pred=test_data.shape[1], t_final=30, delta_t=0.02)\n",
    "x_dmd = x_dmd_r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(3141, figsize=(25,10))\n",
    "ax1 = plt.subplot(1, 2, 1)\n",
    "ax2 = plt.subplot(1, 2, 2)\n",
    "for ii in range(test_data.shape[0]):\n",
    "    ax1.plot(test_data[ii, :, 0], test_data[ii, :, 1], 'r-', lw=0.5)\n",
    "    ax1.plot(x_dmd[ii, :, 0], x_dmd[ii, :, 1], 'b.', ms=0.5)\n",
    "    ax2.plot(test_data[ii, :, 0], test_data[ii, :, 1], 'r-', lw=0.5)\n",
    "    ax2.plot(x_adv[ii, :, 0], x_adv[ii, :, 1], 'b.', ms=0.5)\n",
    "ax1.plot(x_dmd[:, 0, 0], x_dmd[:, 0, 1], 'go', label='initial condition')\n",
    "ax2.plot(x_adv[:, 0, 0], x_adv[:, 0, 1], 'go', label='initial condition')\n",
    "ax1.plot(x_dmd[0, 0, 0], x_dmd[0, 0, 1], 'b.', label='dmd')\n",
    "ax2.plot(x_adv[0, 0, 0], x_adv[0, 0, 1], 'b.', label='dldmd')\n",
    "ax1.plot(test_data[0, :, 0], test_data[0, :, 1], 'r-', lw=0.5, label='test data')\n",
    "ax2.plot(test_data[0, :, 0], test_data[0, :, 1], 'r-', lw=0.5, label='test data')\n",
    "ax1.legend()\n",
    "ax2.legend()\n",
    "ax1.axis('equal')\n",
    "ax2.axis('equal')\n",
    "ax1.set_title('standard DMD')\n",
    "ax2.set_title('DLDMD')\n",
    "plt.suptitle(\"DLDMD vs DMD predictions of nonlinear fluid trajectroies\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(1, figsize=(20,20))\n",
    "ax1 = plt.subplot(2, 2, 1)\n",
    "ax2 = plt.subplot(2, 2, 2)\n",
    "ax3 = plt.subplot(2, 2, 3)\n",
    "ax4 = plt.subplot(2, 2, 4)\n",
    "for ii in range(test_data.shape[0]):\n",
    "    ax1.plot(test_data[ii, :, 0], test_data[ii, :, 1], '-')\n",
    "    ax2.plot(x_adv[ii, :, 0], x_adv[ii, :, 1], '-')\n",
    "    ax3.plot(y_adv[ii, :, 0], y_adv[ii, :, 1], '-')\n",
    "    ax4.plot(x_ae[ii, :, 0], x_ae[ii, :, 1], '-')\n",
    "ax1.plot(test_data[:, 0, 0], test_data[:, 0, 1], '.')\n",
    "ax2.plot(x_adv[:, 0, 0], x_adv[:, 0, 1], '.')\n",
    "ax3.plot(y_adv[:, 0, 0], y_adv[:, 0, 1], '.')\n",
    "ax4.plot(x_ae[:, 0, 0], x_ae[:, 0, 1], '.')\n",
    "ax1.axis('equal')\n",
    "ax1.set_xlim([-3.1, 3.1])\n",
    "ax1.set_ylim([-3.0, 3.0])\n",
    "ax1.set_xlabel(\"$x_1$\", fontsize=fontsize)\n",
    "ax1.set_ylabel(\"$x_2$\", fontsize=fontsize)\n",
    "ax1.set_title(\"Test Data (x)\", fontsize=fontsize)\n",
    "ax2.axis('equal')\n",
    "ax2.set_xlim([-3.1, 3.1])\n",
    "ax2.set_ylim([-3.0, 3.0])\n",
    "ax2.set_xlabel(\"$x_1$\", fontsize=fontsize)\n",
    "ax2.set_ylabel(\"$x_2$\", fontsize=fontsize)\n",
    "ax2.set_title(\"Encoded-Advanced-Decoded (x_adv))\", fontsize=fontsize)\n",
    "ax3.axis('equal')\n",
    "ax3.set_xlabel(\"$y_1$\", fontsize=fontsize)\n",
    "ax3.set_ylabel(\"$y_2$\", fontsize=fontsize)\n",
    "ax3.set_title(\"Encoded-Advanced (y_adv))\", fontsize=fontsize)\n",
    "ax4.axis('equal')\n",
    "ax4.set_xlim([-3.1, 3.1])\n",
    "ax4.set_ylim([-3.0, 3.0])\n",
    "ax4.set_xlabel(\"$x_1$\", fontsize=fontsize)\n",
    "ax4.set_ylabel(\"$x_2$\", fontsize=fontsize)\n",
    "ax4.set_title(\"Encoded-Decoded (x_ae)\", fontsize=fontsize)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eigenvalues\n",
    "angle = np.linspace(0, 2*np.pi, 150)\n",
    "radius = 1.0\n",
    "x = radius * np.cos(angle)\n",
    "y = radius * np.sin(angle)\n",
    "fig = plt.figure(666, figsize=figsize)\n",
    "ax1 = plt.subplot(1, 1, 1)\n",
    "s1 = ax1.scatter(np.real(Lam[:]), np.imag(Lam[:]))\n",
    "ax1.plot(x, y, 'r--')\n",
    "ax1.axis('equal')\n",
    "ax1.set_xlabel(\"$Re(\\lambda)$\", fontsize=fontsize)\n",
    "ax1.set_ylabel(\"$Imag(\\lambda)$\", fontsize=fontsize)\n",
    "ax1.set_title(\"$\\lambda$\", fontsize=fontsize)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

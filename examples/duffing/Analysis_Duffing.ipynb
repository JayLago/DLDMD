{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '../../')\n",
    "import LKBMachine as dl\n",
    "import LossLKB as lf\n",
    "import Data as dat\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# Figure parameters\n",
    "plot_save_path = './analysis_results/'\n",
    "font = {'family': 'DejaVu Sans', 'size': 18}\n",
    "matplotlib.rc('font', **font)\n",
    "fontsize = 18\n",
    "figsize = (15, 10)\n",
    "dpisave = 300\n",
    "\n",
    "# Initialize the compute device\n",
    "DEVICE = '/GPU:0'\n",
    "GPUS = tf.config.experimental.list_physical_devices('GPU')\n",
    "if GPUS:\n",
    "    try:\n",
    "        for gpu in GPUS:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "else:\n",
    "    DEVICE = '/CPU:0'\n",
    "\n",
    "tf.keras.backend.set_floatx('float64')  # !! Set precision for the entire model here\n",
    "print(\"TensorFlow version: {}\".format(tf.__version__))\n",
    "print(\"Eager execution: {}\".format(tf.executing_eagerly()))\n",
    "print(\"Num GPUs available: {}\".format(len(GPUS)))\n",
    "print(\"Training at precision: {}\".format(tf.keras.backend.floatx()))\n",
    "print(\"Training on device: {}\".format(DEVICE))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Load model and data"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# SET THIS PATH (w/o file extension!). Both '.pkl' and '.h5' files should have same name\n",
    "model_path = './trained_models/pendulum_2021-05-25-0954/epoch_100_loss_0.057'\n",
    "model_hyp_params = model_path + '.pkl'\n",
    "model_weights = model_path + '.h5'\n",
    "\n",
    "# Load the hyper parameters\n",
    "hyp_params = pickle.load(open(model_hyp_params, 'rb'))\n",
    "\n",
    "# Set Tensorflow backend precision\n",
    "tf.keras.backend.set_floatx(hyp_params['precision'])\n",
    "print(\"Using precision: {}\\n\".format(tf.keras.backend.floatx()))\n",
    "\n",
    "# Generate test data\n",
    "hyp_params['num_init_conds'] = 20\n",
    "hyp_params['time_final'] = 10\n",
    "hyp_params['num_time_steps'] = int(hyp_params['time_final'] / hyp_params['delta_t'])\n",
    "from scipy.integrate import solve_ivp\n",
    "def vdp(t, x):\n",
    "    return [x[1], mu * (1 - x[0] ** 2) * x[1] - x[0]]\n",
    "mu = hyp_params['mu']\n",
    "icx = np.random.uniform(-2, 2, hyp_params['num_init_conds'])\n",
    "icy = np.random.uniform(-2, 2, hyp_params['num_init_conds'])\n",
    "tspan = np.array([0, hyp_params['time_final']])\n",
    "dts = np.arange(0, hyp_params['time_final'], hyp_params['delta_t'])\n",
    "X = np.zeros(shape=(hyp_params['num_init_conds'], 2, hyp_params['num_time_steps']))\n",
    "for ii, ic in enumerate(zip(icx, icy)):\n",
    "    tmp = solve_ivp(vdp, t_span=tspan, y0=ic, method='RK45', t_eval=dts)\n",
    "    X[ii, :, :] = tmp.y\n",
    "test_data = tf.transpose(X, perm=[0, 2, 1])\n",
    "test_data = tf.cast(test_data, dtype=hyp_params['precision'])\n",
    "print(\"Test data shape: {}\".format(test_data.shape))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using precision: float64\n",
      "\n",
      "Test data shape: (10, 1500, 2)\n"
     ]
    }
   ],
   "source": [
    "# Fix hyper parameters for running the model on test data\n",
    "hyp_params['pretrain'] = False\n",
    "hyp_params['batch_size'] = test_data.shape[0]\n",
    "hyp_params['num_time_steps'] = test_data.shape[1]\n",
    "hyp_params['latent_dim'] = test_data.shape[2]\n",
    "hyp_params['phys_dim'] = test_data.shape[2]\n",
    "\n",
    "# Load the trained DLDMD model weights\n",
    "model = dl.LKBMachine(hyp_params)\n",
    "model.num_pred_steps = hyp_params['num_time_steps']\n",
    "model.time_final = int(hyp_params['num_time_steps'] * model.delta_t)\n",
    "model(test_data)\n",
    "model.load_weights(model_weights)\n",
    "\n",
    "# Initialize the loss function\n",
    "loss = lf.LossLKB(hyp_params)\n",
    "print(\"Number of prediction steps: \", model.num_pred_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Run the trained model"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "with tf.device(DEVICE):\n",
    "    preds = model(test_data, training=False)\n",
    "    losses = loss(preds, test_data)\n",
    "\n",
    "[y, x_ae, x_adv, y_adv, weights, evals_real, evals_cmplx] = preds\n",
    "print(\"Loss: {loss:2.7f}\".format(loss=losses.numpy()))\n",
    "print(\"Log10 Loss: {loss:2.7f}\".format(loss=np.log10(losses.numpy())))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Visualize results"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "fig = plt.figure(3141, figsize=(25,10))\n",
    "ax1 = plt.subplot(1, 1, 1)\n",
    "for ii in range(test_data.shape[0]):\n",
    "    ax1.plot(test_data[ii, :, 0], test_data[ii, :, 1], 'r-', lw=0.5)\n",
    "    ax1.plot(x_adv[ii, :, 0], x_adv[ii, :, 1], 'b.', ms=0.5)\n",
    "ax1.plot(x_adv[:, 0, 0], x_adv[:, 0, 1], 'go', label='initial condition')\n",
    "ax1.plot(x_adv[0, 0, 0], x_adv[0, 0, 1], 'b.', label='LKBMachine')\n",
    "ax1.plot(test_data[0, :, 0], test_data[0, :, 1], 'r-', lw=0.5, label='test data')\n",
    "ax1.legend()\n",
    "ax1.axis('equal')\n",
    "plt.suptitle(\"LKBMachine predictions of nonlinear pendulum phase orbits\")\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(1, figsize=(20,20))\n",
    "ax1 = plt.subplot(2, 2, 1)\n",
    "ax2 = plt.subplot(2, 2, 2)\n",
    "ax3 = plt.subplot(2, 2, 3)\n",
    "ax4 = plt.subplot(2, 2, 4)\n",
    "for ii in range(test_data.shape[0]):\n",
    "    ax1.plot(test_data[ii, :, 0], test_data[ii, :, 1], '-')\n",
    "    ax2.plot(x_adv[ii, :, 0], x_adv[ii, :, 1], '-')\n",
    "    ax3.plot(y_adv[ii, :, 0], y_adv[ii, :, 1], '-')\n",
    "    ax4.plot(x_ae[ii, :, 0], x_ae[ii, :, 1], '-')\n",
    "ax1.plot(test_data[:, 0, 0], test_data[:, 0, 1], '.')\n",
    "ax2.plot(x_adv[:, 0, 0], x_adv[:, 0, 1], '.')\n",
    "ax3.plot(y_adv[:, 0, 0], y_adv[:, 0, 1], '.')\n",
    "ax4.plot(x_ae[:, 0, 0], x_ae[:, 0, 1], '.')\n",
    "ax1.axis('equal')\n",
    "ax1.set_xlim([-3.1, 3.1])\n",
    "ax1.set_ylim([-3.0, 3.0])\n",
    "ax1.set_xlabel(\"$x_1$\", fontsize=fontsize)\n",
    "ax1.set_ylabel(\"$x_2$\", fontsize=fontsize)\n",
    "ax1.set_title(\"Test Data (x)\", fontsize=fontsize)\n",
    "ax2.axis('equal')\n",
    "ax2.set_xlim([-3.1, 3.1])\n",
    "ax2.set_ylim([-3.0, 3.0])\n",
    "ax2.set_xlabel(\"$x_1$\", fontsize=fontsize)\n",
    "ax2.set_ylabel(\"$x_2$\", fontsize=fontsize)\n",
    "ax2.set_title(\"Encoded-Advanced-Decoded (x_adv))\", fontsize=fontsize)\n",
    "ax3.axis('equal')\n",
    "ax3.set_xlabel(\"$y_1$\", fontsize=fontsize)\n",
    "ax3.set_ylabel(\"$y_2$\", fontsize=fontsize)\n",
    "ax3.set_title(\"Encoded-Advanced (y_adv))\", fontsize=fontsize)\n",
    "ax4.axis('equal')\n",
    "ax4.set_xlim([-3.1, 3.1])\n",
    "ax4.set_ylim([-3.0, 3.0])\n",
    "ax4.set_xlabel(\"$x_1$\", fontsize=fontsize)\n",
    "ax4.set_ylabel(\"$x_2$\", fontsize=fontsize)\n",
    "ax4.set_title(\"Encoded-Decoded (x_ae)\", fontsize=fontsize)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
